{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 95, "column": 0}, "map": {"version":3,"sources":["file:///Users/jawa/Projects/MediConnect/lib/supabase.ts"],"sourcesContent":["import { createClient } from \"@supabase/supabase-js\";\n\n// Hardcoded values (for development only)\nconst supabaseUrl = \"https://qfqknamuvypndphwehbl.supabase.co\";\nconst supabaseAnonKey =\n  \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFmcWtuYW11dnlwbmRwaHdlaGJsIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzcyMjc0NTksImV4cCI6MjA1MjgwMzQ1OX0.i3gHL4uQKuM-U5be379PyXvjTaJNUGuKWO6wO0rKd7w\";\n\n// Create the Supabase client\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey);\n\n// Test the connection only in browser\nif (typeof window !== \"undefined\") {\n  async function testConnection() {\n    try {\n      console.log(\"Attempting to connect to Supabase...\");\n      const {\n        data: { session },\n        error,\n      } = await supabase.auth.getSession();\n\n      if (error) {\n        console.error(\"Supabase connection error:\", {\n          message: error.message,\n          status: error.status,\n          name: error.name,\n        });\n      } else {\n        console.log(\"Supabase connection successful\");\n      }\n    } catch (error) {\n      console.error(\"Fatal Supabase connection error:\", {\n        error:\n          error instanceof Error\n            ? {\n                message: error.message,\n                name: error.name,\n                stack: error.stack,\n              }\n            : error,\n      });\n    }\n  }\n\n  testConnection().catch(console.error);\n}\n\nexport type Profile = {\n  id: string;\n  email: string;\n  full_name?: string;\n  avatar_url?: string;\n  updated_at?: string;\n};\n"],"names":[],"mappings":";;;AAAA;;AAEA,0CAA0C;AAC1C,MAAM,cAAc;AACpB,MAAM,kBACJ;AAGK,MAAM,WAAW,CAAA,GAAA,yLAAA,CAAA,eAAY,AAAD,EAAE,aAAa;AAElD,sCAAsC;AACtC,uCAAmC;;IACjC,eAAe;QACb,IAAI;;YAEF,MAAM,EACJ,MAAM,EAAE,OAAO,EAAE,EACjB,KAAK,EACN;YAED,wCAAW;;YAMX,OAAO;;YAEP;QACF,EAAE,OAAO,OAAO;;QAWhB;IACF;AAGF"}},
    {"offset": {"line": 121, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 127, "column": 0}, "map": {"version":3,"sources":["file:///Users/jawa/Projects/MediConnect/lib/embeddings.ts"],"sourcesContent":["import { supabase } from \"./supabase\";\n\n// Improved embedding function\nexport async function getEmbedding(text: string): Promise<number[]> {\n  try {\n    console.log(\"Generating embedding for:\", text.substring(0, 50) + \"...\");\n\n    // Normalize and tokenize the text\n    const normalizedText = text\n      .toLowerCase()\n      .replace(/[^a-z0-9\\s]/g, \"\")\n      .trim()\n      .replace(/\\s+/g, \" \");\n\n    const words = normalizedText.split(/\\s+/);\n\n    // Create a fixed-size embedding (768 dimensions)\n    const embedding = new Array(768).fill(0);\n\n    // For each word, create a more sophisticated embedding\n    words.forEach((word, wordIndex) => {\n      // Use word position for context\n      const positionFactor = (wordIndex + 1) / words.length;\n\n      // Generate word-level features\n      const wordChars = Array.from(word);\n      const wordLength = word.length;\n\n      wordChars.forEach((char, charIndex) => {\n        // Distribute character information across the embedding\n        const charCode = char.charCodeAt(0);\n        const relativePosition = charIndex / wordLength;\n\n        // Use multiple positions for each character to capture more patterns\n        const positions = [\n          (wordIndex * 50 + charIndex) % 768, // Character position\n          (charCode * positionFactor * 10) % 768, // Character value with position weight\n          (wordLength * 20 + charIndex * 3) % 768, // Word length features\n        ];\n\n        positions.forEach((pos) => {\n          embedding[pos] =\n            (embedding[pos] + (charCode / 255) * (1 - relativePosition)) / 2;\n        });\n      });\n    });\n\n    // Normalize the embedding\n    const magnitude = Math.sqrt(\n      embedding.reduce((sum, val) => sum + val * val, 0)\n    );\n    const normalizedEmbedding = embedding.map((val) => val / (magnitude || 1));\n\n    console.log(`Generated embedding of length ${normalizedEmbedding.length}`);\n    return normalizedEmbedding;\n  } catch (error) {\n    console.error(\"Error generating embedding:\", error);\n    if (error instanceof Error) {\n      console.error(\"Error details:\", error.message);\n      console.error(\"Error stack:\", error.stack);\n    }\n    throw error;\n  }\n}\n\nfunction normalizeText(text: string): string {\n  return text\n    .toLowerCase()\n    .trim()\n    .replace(/[^a-z0-9\\s]/g, \"\")\n    .replace(/\\s+/g, \" \");\n}\n\nfunction calculateSimilarity(text1: string, text2: string): number {\n  const normalized1 = normalizeText(text1);\n  const normalized2 = normalizeText(text2);\n\n  // Exact match\n  if (normalized1 === normalized2) return 1;\n\n  const words1 = normalized1.split(\" \");\n  const words2 = normalized2.split(\" \");\n\n  // If lengths are too different, reduce similarity\n  const lengthDiff = Math.abs(words1.length - words2.length);\n  if (lengthDiff > Math.min(words1.length, words2.length)) {\n    return 0.1;\n  }\n\n  // Calculate word-level similarity with position importance\n  let matchScore = 0;\n  let totalScore = Math.max(words1.length, words2.length);\n\n  for (let i = 0; i < words1.length; i++) {\n    const word1 = words1[i];\n    let bestWordMatch = 0;\n\n    for (let j = 0; j < words2.length; j++) {\n      const word2 = words2[j];\n      let wordSimilarity = 0;\n\n      // Exact word match with position bonus\n      if (word1 === word2) {\n        const positionDiff = Math.abs(i - j);\n        const positionPenalty =\n          positionDiff / Math.max(words1.length, words2.length);\n        wordSimilarity = 1 - positionPenalty * 0.5; // Position affects up to 50% of word score\n      }\n      // Partial match for longer words (minimum 4 characters)\n      else if (word1.length >= 4 && word2.length >= 4) {\n        // Check for substring match\n        if (word1.includes(word2) || word2.includes(word1)) {\n          wordSimilarity = 0.7;\n        } else {\n          // Calculate character-level similarity\n          const commonChars = [...word1].filter((char) =>\n            word2.includes(char)\n          ).length;\n          const charSimilarity =\n            commonChars / Math.max(word1.length, word2.length);\n\n          // Only count if significant character overlap\n          if (charSimilarity > 0.6) {\n            wordSimilarity = charSimilarity * 0.5; // Character similarity worth up to 50%\n          }\n        }\n      }\n\n      bestWordMatch = Math.max(bestWordMatch, wordSimilarity);\n    }\n\n    // Apply word position importance\n    const positionImportance = 1 - (i / words1.length) * 0.3; // Earlier words are more important\n    matchScore += bestWordMatch * positionImportance;\n  }\n\n  // Calculate final similarity score\n  let similarity = matchScore / totalScore;\n\n  // Additional penalties for significant differences\n  if (words1.length !== words2.length) {\n    similarity *= 0.9; // 10% penalty for different lengths\n  }\n\n  // Threshold to avoid very low similarity matches\n  return similarity < 0.3 ? 0 : similarity;\n}\n\nexport async function findSimilarQuestions(\n  question: string,\n  threshold = 0.3 // Lowered threshold for better matching\n): Promise<{ question: string; answer: string } | null> {\n  try {\n    const normalizedQuestion = normalizeText(question);\n    console.log(\"Finding similar questions for:\", normalizedQuestion);\n\n    // First try direct text matching\n    const { data: directMatches } = await supabase\n      .from(\"conversations\")\n      .select(\"question, answer\")\n      .ilike(\"question\", `%${normalizedQuestion}%`)\n      .limit(5);\n\n    if (directMatches?.length) {\n      console.log(\"Found direct matches:\", directMatches.length);\n      const bestDirectMatch = directMatches.reduce(\n        (best: any, current: any) => {\n          const similarity = calculateSimilarity(\n            normalizedQuestion,\n            current.question\n          );\n          return similarity > (best?.similarity || 0)\n            ? { ...current, similarity }\n            : best;\n        },\n        null\n      );\n\n      if (bestDirectMatch?.similarity >= threshold) {\n        console.log(\"Best direct match:\", bestDirectMatch);\n        return {\n          question: bestDirectMatch.question,\n          answer: bestDirectMatch.answer,\n        };\n      }\n    }\n\n    // If no direct matches, try vector similarity\n    const questionEmbedding = await getEmbedding(normalizedQuestion);\n    const { data: similarQuestions, error } = await supabase.rpc(\n      \"match_questions\",\n      {\n        query_embedding: questionEmbedding,\n        match_threshold: 0.1, // Lowered threshold for vector similarity\n        match_count: 10,\n      }\n    );\n\n    if (error) {\n      console.error(\"Error in match_questions RPC:\", error);\n      return null;\n    }\n\n    if (!similarQuestions?.length) {\n      console.log(\"No similar questions found\");\n      return null;\n    }\n\n    console.log(\"Found potential matches:\", similarQuestions.length);\n\n    // Find best match using both vector and text similarity\n    const bestMatch = similarQuestions.reduce((best: any, current: any) => {\n      const similarity = calculateSimilarity(\n        normalizedQuestion,\n        current.question\n      );\n      console.log(`Similarity for \"${current.question}\": ${similarity}`);\n      return similarity > (best?.similarity || 0)\n        ? { ...current, similarity }\n        : best;\n    }, null);\n\n    if (bestMatch?.similarity >= threshold) {\n      console.log(\"Best match found:\", bestMatch);\n      return {\n        question: bestMatch.question,\n        answer: bestMatch.answer,\n      };\n    }\n\n    console.log(\"No match above threshold found\");\n    return null;\n  } catch (error) {\n    console.error(\"Error finding similar questions:\", error);\n    return null;\n  }\n}\n\nexport async function storeConversation(question: string, answer: string) {\n  try {\n    const normalizedQuestion = normalizeText(question);\n    const embedding = await getEmbedding(normalizedQuestion);\n\n    const { data: existing } = await supabase\n      .from(\"conversations\")\n      .select(\"id, question\")\n      .eq(\"question\", normalizedQuestion)\n      .limit(1);\n\n    if (existing?.length) {\n      return existing[0];\n    }\n\n    const similarQuestion = await findSimilarQuestions(normalizedQuestion, 0.9);\n    if (similarQuestion) {\n      return similarQuestion;\n    }\n\n    const { data, error } = await supabase\n      .from(\"conversations\")\n      .insert([\n        {\n          question: normalizedQuestion,\n          answer,\n          embedding,\n        },\n      ])\n      .select();\n\n    if (error) {\n      throw error;\n    }\n\n    return data?.[0] || null;\n  } catch (error) {\n    console.error(\"Error storing conversation:\", error);\n    throw error;\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA;;AAGO,eAAe,aAAa,IAAY;IAC7C,IAAI;QACF,QAAQ,GAAG,CAAC,6BAA6B,KAAK,SAAS,CAAC,GAAG,MAAM;QAEjE,kCAAkC;QAClC,MAAM,iBAAiB,KACpB,WAAW,GACX,OAAO,CAAC,gBAAgB,IACxB,IAAI,GACJ,OAAO,CAAC,QAAQ;QAEnB,MAAM,QAAQ,eAAe,KAAK,CAAC;QAEnC,iDAAiD;QACjD,MAAM,YAAY,IAAI,MAAM,KAAK,IAAI,CAAC;QAEtC,uDAAuD;QACvD,MAAM,OAAO,CAAC,CAAC,MAAM;YACnB,gCAAgC;YAChC,MAAM,iBAAiB,CAAC,YAAY,CAAC,IAAI,MAAM,MAAM;YAErD,+BAA+B;YAC/B,MAAM,YAAY,MAAM,IAAI,CAAC;YAC7B,MAAM,aAAa,KAAK,MAAM;YAE9B,UAAU,OAAO,CAAC,CAAC,MAAM;gBACvB,wDAAwD;gBACxD,MAAM,WAAW,KAAK,UAAU,CAAC;gBACjC,MAAM,mBAAmB,YAAY;gBAErC,qEAAqE;gBACrE,MAAM,YAAY;oBAChB,CAAC,YAAY,KAAK,SAAS,IAAI;oBAC9B,WAAW,iBAAiB,KAAM;oBACnC,CAAC,aAAa,KAAK,YAAY,CAAC,IAAI;iBACrC;gBAED,UAAU,OAAO,CAAC,CAAC;oBACjB,SAAS,CAAC,IAAI,GACZ,CAAC,SAAS,CAAC,IAAI,GAAG,AAAC,WAAW,MAAO,CAAC,IAAI,gBAAgB,CAAC,IAAI;gBACnE;YACF;QACF;QAEA,0BAA0B;QAC1B,MAAM,YAAY,KAAK,IAAI,CACzB,UAAU,MAAM,CAAC,CAAC,KAAK,MAAQ,MAAM,MAAM,KAAK;QAElD,MAAM,sBAAsB,UAAU,GAAG,CAAC,CAAC,MAAQ,MAAM,CAAC,aAAa,CAAC;QAExE,QAAQ,GAAG,CAAC,CAAC,8BAA8B,EAAE,oBAAoB,MAAM,EAAE;QACzE,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,+BAA+B;QAC7C,IAAI,iBAAiB,OAAO;YAC1B,QAAQ,KAAK,CAAC,kBAAkB,MAAM,OAAO;YAC7C,QAAQ,KAAK,CAAC,gBAAgB,MAAM,KAAK;QAC3C;QACA,MAAM;IACR;AACF;AAEA,SAAS,cAAc,IAAY;IACjC,OAAO,KACJ,WAAW,GACX,IAAI,GACJ,OAAO,CAAC,gBAAgB,IACxB,OAAO,CAAC,QAAQ;AACrB;AAEA,SAAS,oBAAoB,KAAa,EAAE,KAAa;IACvD,MAAM,cAAc,cAAc;IAClC,MAAM,cAAc,cAAc;IAElC,cAAc;IACd,IAAI,gBAAgB,aAAa,OAAO;IAExC,MAAM,SAAS,YAAY,KAAK,CAAC;IACjC,MAAM,SAAS,YAAY,KAAK,CAAC;IAEjC,kDAAkD;IAClD,MAAM,aAAa,KAAK,GAAG,CAAC,OAAO,MAAM,GAAG,OAAO,MAAM;IACzD,IAAI,aAAa,KAAK,GAAG,CAAC,OAAO,MAAM,EAAE,OAAO,MAAM,GAAG;QACvD,OAAO;IACT;IAEA,2DAA2D;IAC3D,IAAI,aAAa;IACjB,IAAI,aAAa,KAAK,GAAG,CAAC,OAAO,MAAM,EAAE,OAAO,MAAM;IAEtD,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,MAAM,EAAE,IAAK;QACtC,MAAM,QAAQ,MAAM,CAAC,EAAE;QACvB,IAAI,gBAAgB;QAEpB,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,MAAM,EAAE,IAAK;YACtC,MAAM,QAAQ,MAAM,CAAC,EAAE;YACvB,IAAI,iBAAiB;YAErB,uCAAuC;YACvC,IAAI,UAAU,OAAO;gBACnB,MAAM,eAAe,KAAK,GAAG,CAAC,IAAI;gBAClC,MAAM,kBACJ,eAAe,KAAK,GAAG,CAAC,OAAO,MAAM,EAAE,OAAO,MAAM;gBACtD,iBAAiB,IAAI,kBAAkB,KAAK,2CAA2C;YACzF,OAEK,IAAI,MAAM,MAAM,IAAI,KAAK,MAAM,MAAM,IAAI,GAAG;gBAC/C,4BAA4B;gBAC5B,IAAI,MAAM,QAAQ,CAAC,UAAU,MAAM,QAAQ,CAAC,QAAQ;oBAClD,iBAAiB;gBACnB,OAAO;oBACL,uCAAuC;oBACvC,MAAM,cAAc;2BAAI;qBAAM,CAAC,MAAM,CAAC,CAAC,OACrC,MAAM,QAAQ,CAAC,OACf,MAAM;oBACR,MAAM,iBACJ,cAAc,KAAK,GAAG,CAAC,MAAM,MAAM,EAAE,MAAM,MAAM;oBAEnD,8CAA8C;oBAC9C,IAAI,iBAAiB,KAAK;wBACxB,iBAAiB,iBAAiB,KAAK,uCAAuC;oBAChF;gBACF;YACF;YAEA,gBAAgB,KAAK,GAAG,CAAC,eAAe;QAC1C;QAEA,iCAAiC;QACjC,MAAM,qBAAqB,IAAI,AAAC,IAAI,OAAO,MAAM,GAAI,KAAK,mCAAmC;QAC7F,cAAc,gBAAgB;IAChC;IAEA,mCAAmC;IACnC,IAAI,aAAa,aAAa;IAE9B,mDAAmD;IACnD,IAAI,OAAO,MAAM,KAAK,OAAO,MAAM,EAAE;QACnC,cAAc,KAAK,oCAAoC;IACzD;IAEA,iDAAiD;IACjD,OAAO,aAAa,MAAM,IAAI;AAChC;AAEO,eAAe,qBACpB,QAAgB,EAChB,YAAY,IAAI,wCAAwC;AAAzC;IAEf,IAAI;QACF,MAAM,qBAAqB,cAAc;QACzC,QAAQ,GAAG,CAAC,kCAAkC;QAE9C,iCAAiC;QACjC,MAAM,EAAE,MAAM,aAAa,EAAE,GAAG,MAAM,iHAAA,CAAA,WAAQ,CAC3C,IAAI,CAAC,iBACL,MAAM,CAAC,oBACP,KAAK,CAAC,YAAY,CAAC,CAAC,EAAE,mBAAmB,CAAC,CAAC,EAC3C,KAAK,CAAC;QAET,IAAI,eAAe,QAAQ;YACzB,QAAQ,GAAG,CAAC,yBAAyB,cAAc,MAAM;YACzD,MAAM,kBAAkB,cAAc,MAAM,CAC1C,CAAC,MAAW;gBACV,MAAM,aAAa,oBACjB,oBACA,QAAQ,QAAQ;gBAElB,OAAO,aAAa,CAAC,MAAM,cAAc,CAAC,IACtC;oBAAE,GAAG,OAAO;oBAAE;gBAAW,IACzB;YACN,GACA;YAGF,IAAI,iBAAiB,cAAc,WAAW;gBAC5C,QAAQ,GAAG,CAAC,sBAAsB;gBAClC,OAAO;oBACL,UAAU,gBAAgB,QAAQ;oBAClC,QAAQ,gBAAgB,MAAM;gBAChC;YACF;QACF;QAEA,8CAA8C;QAC9C,MAAM,oBAAoB,MAAM,aAAa;QAC7C,MAAM,EAAE,MAAM,gBAAgB,EAAE,KAAK,EAAE,GAAG,MAAM,iHAAA,CAAA,WAAQ,CAAC,GAAG,CAC1D,mBACA;YACE,iBAAiB;YACjB,iBAAiB;YACjB,aAAa;QACf;QAGF,IAAI,OAAO;YACT,QAAQ,KAAK,CAAC,iCAAiC;YAC/C,OAAO;QACT;QAEA,IAAI,CAAC,kBAAkB,QAAQ;YAC7B,QAAQ,GAAG,CAAC;YACZ,OAAO;QACT;QAEA,QAAQ,GAAG,CAAC,4BAA4B,iBAAiB,MAAM;QAE/D,wDAAwD;QACxD,MAAM,YAAY,iBAAiB,MAAM,CAAC,CAAC,MAAW;YACpD,MAAM,aAAa,oBACjB,oBACA,QAAQ,QAAQ;YAElB,QAAQ,GAAG,CAAC,CAAC,gBAAgB,EAAE,QAAQ,QAAQ,CAAC,GAAG,EAAE,YAAY;YACjE,OAAO,aAAa,CAAC,MAAM,cAAc,CAAC,IACtC;gBAAE,GAAG,OAAO;gBAAE;YAAW,IACzB;QACN,GAAG;QAEH,IAAI,WAAW,cAAc,WAAW;YACtC,QAAQ,GAAG,CAAC,qBAAqB;YACjC,OAAO;gBACL,UAAU,UAAU,QAAQ;gBAC5B,QAAQ,UAAU,MAAM;YAC1B;QACF;QAEA,QAAQ,GAAG,CAAC;QACZ,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,oCAAoC;QAClD,OAAO;IACT;AACF;AAEO,eAAe,kBAAkB,QAAgB,EAAE,MAAc;IACtE,IAAI;QACF,MAAM,qBAAqB,cAAc;QACzC,MAAM,YAAY,MAAM,aAAa;QAErC,MAAM,EAAE,MAAM,QAAQ,EAAE,GAAG,MAAM,iHAAA,CAAA,WAAQ,CACtC,IAAI,CAAC,iBACL,MAAM,CAAC,gBACP,EAAE,CAAC,YAAY,oBACf,KAAK,CAAC;QAET,IAAI,UAAU,QAAQ;YACpB,OAAO,QAAQ,CAAC,EAAE;QACpB;QAEA,MAAM,kBAAkB,MAAM,qBAAqB,oBAAoB;QACvE,IAAI,iBAAiB;YACnB,OAAO;QACT;QAEA,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,iHAAA,CAAA,WAAQ,CACnC,IAAI,CAAC,iBACL,MAAM,CAAC;YACN;gBACE,UAAU;gBACV;gBACA;YACF;SACD,EACA,MAAM;QAET,IAAI,OAAO;YACT,MAAM;QACR;QAEA,OAAO,MAAM,CAAC,EAAE,IAAI;IACtB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,+BAA+B;QAC7C,MAAM;IACR;AACF"}},
    {"offset": {"line": 329, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 335, "column": 0}, "map": {"version":3,"sources":["file:///Users/jawa/Projects/MediConnect/app/api/chat/route.ts"],"sourcesContent":["import { GoogleGenerativeAI } from \"@google/generative-ai\";\nimport { findSimilarQuestions, storeConversation } from \"@/lib/embeddings\";\nimport { supabase } from \"@/lib/supabase\";\n\n// Initialize Gemini with hardcoded API key for now\nconst genAI = new GoogleGenerativeAI(\"AIzaSyBVdtTryQ4U__ThmJVpX1DHCRmDBIme7DU\");\n\n// Get the chat model\nconst model = genAI.getGenerativeModel({ model: \"gemini-pro\" });\n\nasync function checkForAnswer(question: string) {\n  const { data: conversations, error } = await supabase\n    .from(\"conversations\")\n    .select(\"answer\")\n    .eq(\"question\", question)\n    .limit(1)\n    .single();\n\n  if (error || !conversations) {\n    return null;\n  }\n\n  return conversations.answer;\n}\n\nexport async function POST(req: Request) {\n  try {\n    const body = await req.json();\n    const question = body.message;\n\n    console.log(\"Received question:\", question);\n\n    // First check for similar questions in the database\n    const similarQuestion = await findSimilarQuestions(question);\n    if (similarQuestion) {\n      console.log(\"Found similar question:\", similarQuestion);\n      return new Response(\n        JSON.stringify({\n          response: similarQuestion.answer,\n          source: \"database\",\n        })\n      );\n    }\n\n    // Check if this question has been answered by staff\n    const staffAnswer = await checkForAnswer(question);\n    if (staffAnswer) {\n      return new Response(\n        JSON.stringify({\n          response: staffAnswer,\n          source: \"staff\",\n        })\n      );\n    }\n\n    // If no similar question found, use Gemini to generate an answer\n    const chat = model.startChat({\n      generationConfig: {\n        temperature: 0.7,\n        topK: 1,\n        topP: 1,\n        maxOutputTokens: 2048,\n      },\n    });\n\n    const result = await chat.sendMessage(question);\n    const response = await result.response;\n    const answer = response.text();\n\n    if (!answer) {\n      throw new Error(\"Empty response from Gemini\");\n    }\n\n    return new Response(\n      JSON.stringify({\n        response: answer,\n        source: \"gemini\",\n      })\n    );\n  } catch (error) {\n    console.error(\"Error in chat route:\", error);\n    return new Response(\n      JSON.stringify({\n        error: \"Failed to process request\",\n        details: error instanceof Error ? error.message : String(error),\n      }),\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;AAAA;AACA;AACA;;;;AAEA,mDAAmD;AACnD,MAAM,QAAQ,IAAI,gKAAA,CAAA,qBAAkB,CAAC;AAErC,qBAAqB;AACrB,MAAM,QAAQ,MAAM,kBAAkB,CAAC;IAAE,OAAO;AAAa;AAE7D,eAAe,eAAe,QAAgB;IAC5C,MAAM,EAAE,MAAM,aAAa,EAAE,KAAK,EAAE,GAAG,MAAM,iHAAA,CAAA,WAAQ,CAClD,IAAI,CAAC,iBACL,MAAM,CAAC,UACP,EAAE,CAAC,YAAY,UACf,KAAK,CAAC,GACN,MAAM;IAET,IAAI,SAAS,CAAC,eAAe;QAC3B,OAAO;IACT;IAEA,OAAO,cAAc,MAAM;AAC7B;AAEO,eAAe,KAAK,GAAY;IACrC,IAAI;QACF,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,MAAM,WAAW,KAAK,OAAO;QAE7B,QAAQ,GAAG,CAAC,sBAAsB;QAElC,oDAAoD;QACpD,MAAM,kBAAkB,MAAM,CAAA,GAAA,mHAAA,CAAA,uBAAoB,AAAD,EAAE;QACnD,IAAI,iBAAiB;YACnB,QAAQ,GAAG,CAAC,2BAA2B;YACvC,OAAO,IAAI,SACT,KAAK,SAAS,CAAC;gBACb,UAAU,gBAAgB,MAAM;gBAChC,QAAQ;YACV;QAEJ;QAEA,oDAAoD;QACpD,MAAM,cAAc,MAAM,eAAe;QACzC,IAAI,aAAa;YACf,OAAO,IAAI,SACT,KAAK,SAAS,CAAC;gBACb,UAAU;gBACV,QAAQ;YACV;QAEJ;QAEA,iEAAiE;QACjE,MAAM,OAAO,MAAM,SAAS,CAAC;YAC3B,kBAAkB;gBAChB,aAAa;gBACb,MAAM;gBACN,MAAM;gBACN,iBAAiB;YACnB;QACF;QAEA,MAAM,SAAS,MAAM,KAAK,WAAW,CAAC;QACtC,MAAM,WAAW,MAAM,OAAO,QAAQ;QACtC,MAAM,SAAS,SAAS,IAAI;QAE5B,IAAI,CAAC,QAAQ;YACX,MAAM,IAAI,MAAM;QAClB;QAEA,OAAO,IAAI,SACT,KAAK,SAAS,CAAC;YACb,UAAU;YACV,QAAQ;QACV;IAEJ,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wBAAwB;QACtC,OAAO,IAAI,SACT,KAAK,SAAS,CAAC;YACb,OAAO;YACP,SAAS,iBAAiB,QAAQ,MAAM,OAAO,GAAG,OAAO;QAC3D,IACA;YAAE,QAAQ;QAAI;IAElB;AACF"}},
    {"offset": {"line": 408, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}